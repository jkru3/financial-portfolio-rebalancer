{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL for the Wikipedia page with the S&P 500 list\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "# Send a request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Parse the page content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the S&P 500 companies\n",
    "table = soup.find('table', {'class': 'wikitable'})\n",
    "\n",
    "# Use pandas to parse the table\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "# Get the list of tickers from the 'Symbol' column\n",
    "tickers_list = [ticker for ticker in df['Symbol'].tolist() if ticker.isalpha()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import time\n",
    "\n",
    "# Specify the number of years back\n",
    "years_back = 1\n",
    "cooldown = 1 # seconds between API calls\n",
    "output_file = './data/stock_data.csv'\n",
    "\n",
    "# Initialize variables\n",
    "all_stock_data = []\n",
    "skipped_stocks = []\n",
    "start_date = pd.Timestamp.now() - pd.DateOffset(years=years_back)\n",
    "end_date = pd.Timestamp.now()\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers_list:\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        sector = yf.Ticker(ticker)\n",
    "        stock_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        info = sector.info\n",
    "        \n",
    "        # Skip stock if we can't get fundamental data on it\n",
    "        if not info.get(\"sector\") or info.get(\"sector\") == \"\":\n",
    "            skipped_stocks.append(ticker)\n",
    "            continue\n",
    "\n",
    "        # Loop through each row in stock data\n",
    "        for date, row in stock_data.iterrows():\n",
    "            all_stock_data.append([\n",
    "                ticker,\n",
    "                info.get(\"sector\"),\n",
    "                date.strftime(\"%Y-%m-%d\"),\n",
    "                row[\"Close\"].values[0],\n",
    "                row[\"Open\"].values[0],\n",
    "                row[\"Low\"].values[0],\n",
    "                row[\"High\"].values[0],\n",
    "                row[\"Volume\"].values[0]\n",
    "            ])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "        skipped_stocks.append(ticker)\n",
    "        continue\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time < cooldown:\n",
    "        time.sleep(cooldown - elapsed_time)\n",
    "\n",
    "# Create DataFrame from new data\n",
    "columns = [\"ticker\", \"sector\", \"date\", \"close\", \"open\", \"low\", \"high\", \"volume\"]\n",
    "stock_data_df = pd.DataFrame(all_stock_data, columns=columns)\n",
    "\n",
    "# Save the updated data\n",
    "stock_data_df.to_csv(output_file, index=False)\n",
    "print(f\"Skipped tickers: {skipped_stocks}\")\n",
    "print(f\"Stock data saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
